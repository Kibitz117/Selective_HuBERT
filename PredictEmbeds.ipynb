{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0acbe00e-be02-4e4f-ae0f-483a1838ea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42680/1384774970.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from transformers.optimization import AdamW\n",
    "from transformers import HubertModel, AutoConfig\n",
    "\n",
    "from models.hubert_selective import HuBERTSelectiveNet\n",
    "from utils.model_tools import *\n",
    "from utils.selective_loss import SelectiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0daaba6-2f8d-4759-a666-1e34affa8d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd01783-2d2c-42f3-8a3f-c592a50c7ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000Animal_Domestic animals_ pets_Cat_Growling_reference.wav', '001Animal_Domestic animals_ pets_Cat_Hiss_reference.wav', '002Animal_Domestic animals_ pets_Cat_Meow_reference.wav', '003Animal_Domestic animals_ pets_Cat_Purr_reference.wav', '004Animal_Domestic animals_ pets_Dog_Bark_reference.wav']\n",
      "{'Animal', 'Sounds of things', 'Source-ambiguous sounds', 'Natural sounds', 'Channel', 'Music', 'Human sounds'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "embeds_folder = 'embeds/vocal_imitation-v1.1.3-full'\n",
    "\n",
    "labels = []\n",
    "\n",
    "with open(embeds_folder + '/labelvocabulary.csv', mode='r', encoding='utf-8') as file:\n",
    "    label_csv = csv.DictReader(file)\n",
    "    for row in label_csv:\n",
    "        labels.append(row['label'])\n",
    "\n",
    "print(labels[:5])\n",
    "\n",
    "classes = set([filename[3:].split('_')[0] for filename in labels])\n",
    "print(classes)\n",
    "\n",
    "def get_class(label):\n",
    "    return label[3:].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6500775-f4d9-44bc-b0b3-fefc978bc579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal 0.16535121101205036\n",
      "Sounds of things 0.07952992817010536\n",
      "Source-ambiguous sounds 0.06819154399178363\n",
      "Natural sounds 0.05687169312169312\n",
      "Channel 0.09629877369007804\n",
      "Music 0.1090071789969681\n",
      "Human sounds 0.19200464411164817\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def get_percent_correct_per_class(foldname):\n",
    "    with open(f'{embeds_folder}/{foldname}.target-labels.pkl', 'rb') as file:\n",
    "        targetlabels = pickle.load(file)\n",
    "    \n",
    "    with open(f'{embeds_folder}/{foldname}.predictions.pkl', 'rb') as file:\n",
    "        predictions = pickle.load(file)\n",
    "    \n",
    "    correct_classes = {key: 0 for key in classes}\n",
    "    total_classes = {key: 0 for key in classes}\n",
    "    \n",
    "    for target, pred in zip(targetlabels, predictions['prediction']):\n",
    "        label_idx = labels.index(target[0])\n",
    "        pred_idx = torch.argmax(pred).item()\n",
    "        label_class = get_class(target[0])\n",
    "        total_classes[label_class] += 1\n",
    "        if label_idx == pred_idx:\n",
    "            correct_classes[label_class] += 1\n",
    "    \n",
    "    for key, value in correct_classes.items():\n",
    "        correct_classes[key] = value / total_classes[key]\n",
    "    \n",
    "    return correct_classes\n",
    "\n",
    "fold00 = get_percent_correct_per_class('fold00')\n",
    "fold01 = get_percent_correct_per_class('fold01')\n",
    "fold02 = get_percent_correct_per_class('fold02')\n",
    "\n",
    "for key, value in fold00.items():\n",
    "    print(key, (value + fold01[key] + fold02[key])/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b219ed-d418-4db6-8f8b-6d27bce271a7",
   "metadata": {},
   "source": [
    "### Take a look at embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78557695-8e52-4dd3-9602-4835c26d423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "fold00_embed = np.load(f'embeds/vocal_imitation-v1.1.3-full/fold00/000Animal_Domestic animals_ pets_Cat_Growling-4815397341626368.wav.embedding.npy', allow_pickle=True)\n",
    "print(fold00_embed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "104157e4-2eab-4d05-be6d-41f9cb95c22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeds/vocal_imitation-v1.1.3-full/fold00/000Animal_Domestic animals_ pets_Cat_Growling-4815397341626368.wav.embedding.npy\n",
    "# embeds/vocal_imitation-v1.1.3-full/fold00/000Animal_Domestic animals_ pets_Cat_Growling-4815397341626368.wav.target-labels.json\n",
    "\n",
    "int('032Animal_Domestic animals_ '[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76853992-2687-4b05-84d6-d171307b86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsDataset(Dataset):\n",
    "    def __init__(self, data_dir, fold_name, vocab_file='labelvocabulary.csv'):\n",
    "        vocab_path = os.path.join(data_dir, vocab_file)\n",
    "        \n",
    "        if os.path.exists(vocab_path):\n",
    "            self.vocab_list = read_csv(vocab_path)\n",
    "        else:\n",
    "            raise Exception(\"Data folder must contain a valid vocab index csv file\")\n",
    "\n",
    "        fold_label_file = fold_name + '.json'\n",
    "        label_path = os.path.join(data_dir, fold_label_file)\n",
    "    \n",
    "        with open(label_path, mode='r') as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "        self.samples = list(data.keys())\n",
    "        \n",
    "        self.fold_name = fold_name\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx] + '.embedding.npy'\n",
    "        embed_path = os.path.join(self.data_dir, self.fold_name, sample)\n",
    "        embeddings = np.load(embed_path)\n",
    "        \n",
    "        embeddings = torch.from_numpy(embeddings)\n",
    "        label = torch.tensor(int(sample[:3]), dtype=torch.int16)\n",
    "        return [embeddings, label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe137a-7156-41fc-ac1e-3a04b85ada34",
   "metadata": {},
   "source": [
    "### Train SelectiveNet on Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d5cbfe-eedd-4010-9153-7e05589abc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotToCrossEntropyLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneHotToCrossEntropyLoss, self).__init__()\n",
    "        # Set reduction to 'none' to get a loss per item in the batch\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, y_hat: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        print(y_hat.shape)\n",
    "        print(y.shape)\n",
    "        # One and only one label per class\n",
    "        assert torch.all(\n",
    "            torch.sum(y, dim=1) == torch.tensor(1., device=y.device)\n",
    "        )\n",
    "        y = y.argmax(dim=1)\n",
    "        # This will now return a tensor of shape (B,)\n",
    "        return self.loss(y_hat, y)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()#OneHotToCrossEntropyLoss()\n",
    "\n",
    "fold00 = EmbeddingsDataset(embeds_folder, fold_name='fold00')\n",
    "fold01 = EmbeddingsDataset(embeds_folder, fold_name='fold01')\n",
    "fold02 = EmbeddingsDataset(embeds_folder, fold_name='fold02')\n",
    "\n",
    "#for embed, label in fold00:\n",
    "#    print(embed.shape)\n",
    "#    print(label)\n",
    "\n",
    "coverage = 0.8\n",
    "alpha = 0.5\n",
    "lm = 32.0\n",
    "num_classes = 302\n",
    "feature_size = 768\n",
    "\n",
    "num_epochs = 500\n",
    "batch_size = 200\n",
    "\n",
    "model = HuBERTSelectiveNet(num_classes=num_classes, feature_size=feature_size)\n",
    "loss_fn = SelectiveLoss(loss_func, coverage, alpha, lm, device=device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0032)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "226cdaad-2cf0-42cd-8403-86e5dff9097c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109f0135db6e4480a28c5c6a817c51e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "threshold 0.5\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [10,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [11,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [12,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [13,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [14,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [15,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [16,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [17,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [18,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [19,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [20,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [21,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [22,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [23,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [24,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [25,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [26,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [27,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [28,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [29,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [30,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [31,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m t:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mselective_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m selective_test(test_loader, model, device)\n\u001b[1;32m     24\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "File \u001b[0;32m~/Selective_HuBERT/utils/model_tools.py:181\u001b[0m, in \u001b[0;36mselective_train\u001b[0;34m(dataloader, model, selective_loss, optimizer, device)\u001b[0m\n\u001b[1;32m    178\u001b[0m auxiliary_logits\u001b[38;5;241m=\u001b[39mauxiliary_logits\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    180\u001b[0m labels \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mlong() \u001b[38;5;66;03m# TODO just dix this in dataloader\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[43mselective_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mselection_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselection_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mauxiliary_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauxiliary_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    187\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Selective_HuBERT/utils/selective_loss.py:213\u001b[0m, in \u001b[0;36mSelectiveLoss.forward\u001b[0;34m(self, prediction_out, selection_out, auxiliary_out, target, threshold, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m loss_pytorch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m selective_loss \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha) \u001b[38;5;241m*\u001b[39m ce_loss\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# compute coverage based on source implementation\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m selective_head_coverage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselection_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# compute selective accuracy based on source implementation\u001b[39;00m\n\u001b[1;32m    216\u001b[0m selective_head_selective_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_selective_acc(prediction_out, selection_out, target)\n",
      "File \u001b[0;32m~/Selective_HuBERT/utils/selective_loss.py:281\u001b[0m, in \u001b[0;36mSelectiveLoss.get_coverage\u001b[0;34m(self, selection_out, threshold)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mEquivalent to coverage function of source implementation\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m    selection_out:  (B, 1)\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m, threshold)\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mselection_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28mprint\u001b[39m(selection_out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    283\u001b[0m g \u001b[38;5;241m=\u001b[39m (selection_out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:431\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    428\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor_str.py:664\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    663\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor_str.py:595\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    594\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 595\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    598\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor_str.py:347\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    345\u001b[0m     )\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor_str.py:138\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(\n\u001b[0;32m--> 138\u001b[0m         tensor_view, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m tensor_view\u001b[38;5;241m.\u001b[39mne(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "train_losses_file = 'logs/selective-hubert-10ep-80c-train.txt'\n",
    "test_losses_file = 'logs/selective-hubert-10ep-80c-test.txt'\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "t = trange(num_epochs)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "fold_set = set([fold00, fold01, fold02])\n",
    "\n",
    "try:\n",
    "    for fold in fold_set:\n",
    "        off_folds = fold_set.difference([fold])\n",
    "        off_concat = torch.utils.data.ConcatDataset(off_folds)\n",
    "        \n",
    "        train_loader = DataLoader(fold, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "        test_loader = DataLoader(off_concat, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "    \n",
    "        for epoch in t:\n",
    "            print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "            train_loss = selective_train(train_loader, model, loss_fn, optimizer, device)\n",
    "            test_loss = selective_test(test_loader, model, device)\n",
    "            train_losses.append(train_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            torch.save(model.state_dict(), model_file)\n",
    "\n",
    "finally:\n",
    "    with open(train_losses_file, 'w') as fp:\n",
    "        for s in train_losses:\n",
    "            fp.write(\"%s\\n\" % s)\n",
    "            \n",
    "    with open(test_losses_file, 'w') as fp:\n",
    "        for x in test_losses:\n",
    "            fp.write(\"%s\\n\" % x)\n",
    "    \n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72315926-0b41-4c76-82bc-7372a496975d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
