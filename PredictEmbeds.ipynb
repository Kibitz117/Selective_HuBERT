{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0acbe00e-be02-4e4f-ae0f-483a1838ea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_136890/1214064084.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from transformers.optimization import AdamW\n",
    "from transformers import HubertModel, AutoConfig\n",
    "\n",
    "from models.hubert_selective import HuBERTSelectiveNet\n",
    "from utils.model_tools import *\n",
    "from utils.selective_loss import SelectiveLoss\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\" # just for debugging this loss thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0daaba6-2f8d-4759-a666-1e34affa8d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd01783-2d2c-42f3-8a3f-c592a50c7ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000Animal_Domestic animals_ pets_Cat_Growling_reference.wav', '001Animal_Domestic animals_ pets_Cat_Hiss_reference.wav', '002Animal_Domestic animals_ pets_Cat_Meow_reference.wav', '003Animal_Domestic animals_ pets_Cat_Purr_reference.wav', '004Animal_Domestic animals_ pets_Dog_Bark_reference.wav']\n",
      "{'Natural sounds', 'Human sounds', 'Sounds of things', 'Music', 'Animal', 'Channel', 'Source-ambiguous sounds'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "embeds_folder = 'embeds/vocal_imitation-v1.1.3-full'\n",
    "\n",
    "labels = []\n",
    "\n",
    "with open(embeds_folder + '/labelvocabulary.csv', mode='r', encoding='utf-8') as file:\n",
    "    label_csv = csv.DictReader(file)\n",
    "    for row in label_csv:\n",
    "        labels.append(row['label'])\n",
    "\n",
    "print(labels[:5])\n",
    "\n",
    "classes = set([filename[3:].split('_')[0] for filename in labels])\n",
    "print(classes)\n",
    "\n",
    "def get_class(label):\n",
    "    return label[3:].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6500775-f4d9-44bc-b0b3-fefc978bc579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'prediction': tensor([[7.4165e-05, 4.9898e-04, 4.2090e-04,  ..., 7.2377e-04, 2.1606e-04,\n",
      "         3.6174e-02],\n",
      "        [2.9739e-07, 1.8492e-05, 6.0240e-04,  ..., 8.7165e-07, 2.1620e-05,\n",
      "         1.0725e-06],\n",
      "        [2.2136e-02, 1.4008e-04, 1.8936e-05,  ..., 2.1327e-05, 3.8000e-02,\n",
      "         1.5987e-02],\n",
      "        ...,\n",
      "        [1.7235e-04, 5.4822e-06, 5.7101e-06,  ..., 1.2099e-06, 2.6956e-04,\n",
      "         6.9220e-07],\n",
      "        [6.2079e-05, 7.5346e-05, 6.5691e-04,  ..., 2.9677e-04, 7.0809e-05,\n",
      "         1.6825e-03],\n",
      "        [7.8546e-06, 3.9271e-05, 2.6359e-04,  ..., 5.2309e-05, 8.7509e-06,\n",
      "         4.0081e-05]]), 'prediction_logit': tensor([[-3.7811, -1.8748, -2.0450,  ..., -1.5029, -2.7118,  2.4087],\n",
      "        [-7.4342, -3.3042,  0.1794,  ..., -6.3589, -3.1479, -6.1516],\n",
      "        [ 2.2879, -2.7748, -4.7760,  ..., -4.6570,  2.8283,  1.9625],\n",
      "        ...,\n",
      "        [-1.1346, -4.5826, -4.5419,  ..., -6.0936, -0.6873, -6.6520],\n",
      "        [-4.1097, -3.9160, -1.7505,  ..., -2.5451, -3.9781, -0.8101],\n",
      "        [-4.9103, -3.3009, -1.3970,  ..., -3.0142, -4.8022, -3.2805]])}\n",
      "{'target': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'prediction': tensor([[3.3792e-05, 2.2923e-04, 1.2812e-04,  ..., 9.6360e-05, 8.7304e-05,\n",
      "         6.4732e-04],\n",
      "        [4.1606e-04, 3.3462e-04, 3.5852e-06,  ..., 1.3675e-05, 7.4647e-05,\n",
      "         9.9734e-05],\n",
      "        [1.2558e-05, 1.2851e-04, 6.7593e-05,  ..., 4.1867e-05, 1.5703e-04,\n",
      "         1.2360e-04],\n",
      "        ...,\n",
      "        [4.9426e-06, 2.8815e-04, 1.3386e-02,  ..., 7.7694e-06, 1.5621e-04,\n",
      "         2.3163e-06],\n",
      "        [3.8638e-04, 5.9176e-03, 1.1443e-05,  ..., 1.2016e-03, 3.9910e-04,\n",
      "         4.3797e-03],\n",
      "        [5.2763e-05, 1.0120e-02, 7.6540e-02,  ..., 2.6853e-05, 1.5918e-05,\n",
      "         1.0611e-05]]), 'prediction_logit': tensor([[-4.0698, -2.1553, -2.7371,  ..., -3.0220, -3.1207, -1.1172],\n",
      "        [-1.6098, -1.8276, -6.3638,  ..., -5.0251, -3.3279, -3.0381],\n",
      "        [-4.9981, -2.6724, -3.3149,  ..., -3.7939, -2.4720, -2.7113],\n",
      "        ...,\n",
      "        [-4.6881, -0.6225,  3.2160,  ..., -4.2358, -1.2348, -5.4460],\n",
      "        [-1.1056,  1.6233, -4.6251,  ...,  0.0290, -1.0732,  1.3223],\n",
      "        [-3.9244,  1.3321,  3.3553,  ..., -4.5998, -5.1228, -5.5283]])}\n",
      "{'target': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'prediction': tensor([[2.7349e-06, 2.8782e-05, 1.4040e-06,  ..., 1.6687e-05, 4.5171e-06,\n",
      "         2.2144e-04],\n",
      "        [9.3741e-04, 9.4687e-05, 7.5578e-05,  ..., 3.6335e-06, 3.8410e-03,\n",
      "         6.3991e-05],\n",
      "        [7.8042e-07, 5.7395e-06, 1.8690e-06,  ..., 3.2038e-07, 1.2939e-06,\n",
      "         2.0799e-05],\n",
      "        ...,\n",
      "        [6.9679e-06, 3.5436e-04, 2.1027e-06,  ..., 1.0017e-03, 8.2158e-04,\n",
      "         2.9045e-05],\n",
      "        [2.5387e-07, 8.6457e-07, 4.6303e-08,  ..., 1.0797e-04, 1.7837e-05,\n",
      "         2.6826e-07],\n",
      "        [7.7601e-04, 1.1257e-04, 2.1428e-07,  ..., 6.6353e-06, 8.7537e-03,\n",
      "         9.0019e-05]]), 'prediction_logit': tensor([[-3.9470, -1.5933, -4.6137,  ..., -2.1384, -3.4452,  0.4471],\n",
      "        [-1.0356, -3.3281, -3.5535,  ..., -6.5885,  0.3748, -3.7199],\n",
      "        [-4.1325, -2.1373, -3.2592,  ..., -5.0229, -3.6270, -0.8497],\n",
      "        ...,\n",
      "        [-5.1797, -1.2507, -6.3778,  ..., -0.2116, -0.4098, -3.7522],\n",
      "        [-5.9742, -4.7488, -7.6758,  ...,  0.0786, -1.7220, -5.9191],\n",
      "        [-0.1677, -2.0983, -8.3623,  ..., -4.9294,  2.2554, -2.3218]])}\n",
      "Natural sounds 0.05687169312169312\n",
      "Human sounds 0.19200464411164817\n",
      "Sounds of things 0.07952992817010536\n",
      "Music 0.1090071789969681\n",
      "Animal 0.16535121101205036\n",
      "Channel 0.09629877369007804\n",
      "Source-ambiguous sounds 0.06819154399178363\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def get_percent_correct_per_class(foldname):\n",
    "    with open(f'{embeds_folder}/{foldname}.target-labels.pkl', 'rb') as file:\n",
    "        targetlabels = pickle.load(file)\n",
    "    \n",
    "    with open(f'{embeds_folder}/{foldname}.predictions.pkl', 'rb') as file:\n",
    "        predictions = pickle.load(file)\n",
    "\n",
    "    print(predictions)\n",
    "    \n",
    "    correct_classes = {key: 0 for key in classes}\n",
    "    total_classes = {key: 0 for key in classes}\n",
    "    \n",
    "    for target, pred in zip(targetlabels, predictions['prediction']):\n",
    "        label_idx = labels.index(target[0])\n",
    "        pred_idx = torch.argmax(pred).item()\n",
    "        label_class = get_class(target[0])\n",
    "        total_classes[label_class] += 1\n",
    "        if label_idx == pred_idx:\n",
    "            correct_classes[label_class] += 1\n",
    "    \n",
    "    for key, value in correct_classes.items():\n",
    "        correct_classes[key] = value / total_classes[key]\n",
    "    \n",
    "    return correct_classes\n",
    "\n",
    "fold00 = get_percent_correct_per_class('fold00')\n",
    "fold01 = get_percent_correct_per_class('fold01')\n",
    "fold02 = get_percent_correct_per_class('fold02')\n",
    "\n",
    "for key, value in fold00.items():\n",
    "    print(key, (value + fold01[key] + fold02[key])/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b219ed-d418-4db6-8f8b-6d27bce271a7",
   "metadata": {},
   "source": [
    "### Take a look at embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78557695-8e52-4dd3-9602-4835c26d423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "fold00_embed = np.load(f'embeds/vocal_imitation-v1.1.3-full/fold00/000Animal_Domestic animals_ pets_Cat_Growling-4815397341626368.wav.embedding.npy', allow_pickle=True)\n",
    "print(fold00_embed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "104157e4-2eab-4d05-be6d-41f9cb95c22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeds/vocal_imitation-v1.1.3-full/fold00/000Animal_Domestic animals_ pets_Cat_Growling-4815397341626368.wav.embedding.npy\n",
    "# embeds/vocal_imitation-v1.1.3-full/fold00/000Animal_Domestic animals_ pets_Cat_Growling-4815397341626368.wav.target-labels.json\n",
    "\n",
    "int('032Animal_Domestic animals_ '[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76853992-2687-4b05-84d6-d171307b86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsDataset(Dataset):\n",
    "    def __init__(self, data_dir, fold_name, vocab_file='labelvocabulary.csv'):\n",
    "        vocab_path = os.path.join(data_dir, vocab_file)\n",
    "        \n",
    "        if os.path.exists(vocab_path):\n",
    "            self.vocab_list = read_csv(vocab_path)\n",
    "        else:\n",
    "            raise Exception(\"Data folder must contain a valid vocab index csv file\")\n",
    "\n",
    "        fold_label_file = fold_name + '.json'\n",
    "        label_path = os.path.join(data_dir, fold_label_file)\n",
    "    \n",
    "        with open(label_path, mode='r') as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "        self.samples = list(data.keys())\n",
    "        \n",
    "        self.fold_name = fold_name\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx] + '.embedding.npy'\n",
    "        embed_path = os.path.join(self.data_dir, self.fold_name, sample)\n",
    "        embeddings = np.load(embed_path)\n",
    "        \n",
    "        embeddings = torch.from_numpy(embeddings)\n",
    "        label = torch.tensor(int(sample[:3]), dtype=torch.long)\n",
    "        return [embeddings, label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe137a-7156-41fc-ac1e-3a04b85ada34",
   "metadata": {},
   "source": [
    "### Train SelectiveNet on Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d5cbfe-eedd-4010-9153-7e05589abc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotToCrossEntropyLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneHotToCrossEntropyLoss, self).__init__()\n",
    "        # Set reduction to 'none' to get a loss per item in the batch\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, y_hat: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        print(y_hat.shape)\n",
    "        print(y.shape)\n",
    "        # One and only one label per class\n",
    "        assert torch.all(\n",
    "            torch.sum(y, dim=1) == torch.tensor(1., device=y.device)\n",
    "        )\n",
    "        y = y.argmax(dim=1)\n",
    "        # This will now return a tensor of shape (B,)\n",
    "        return self.loss(y_hat, y)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()#OneHotToCrossEntropyLoss()\n",
    "\n",
    "fold00 = EmbeddingsDataset(embeds_folder, fold_name='fold00')\n",
    "fold01 = EmbeddingsDataset(embeds_folder, fold_name='fold01')\n",
    "fold02 = EmbeddingsDataset(embeds_folder, fold_name='fold02')\n",
    "\n",
    "coverage = 1.0\n",
    "alpha = 0.5\n",
    "lm = 32.0\n",
    "num_classes = 302\n",
    "feature_size = 768\n",
    "\n",
    "num_epochs = 130\n",
    "batch_size = 1024\n",
    "\n",
    "model = HuBERTSelectiveNet(num_classes=num_classes, feature_size=feature_size)\n",
    "loss_fn = SelectiveLoss(loss_func, coverage, alpha, lm, device=device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0032)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "226cdaad-2cf0-42cd-8403-86e5dff9097c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57568d621f0940b0845a2c7e54b232c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 8.282101  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.005512 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 5.822941  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.023093 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 5.214411  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.033871 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.896560  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.041860 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4.698348  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.051488 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 4.546929  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.070917 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 4.395479  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.092614 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 4.316939  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.097778 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 4.185995  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.119580 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 4.094640  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.119826 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 3.985692  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.128127 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 3.934417  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.137895 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 3.871365  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.141068 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 3.800132  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.145079 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 3.719011  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155650 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 3.608016  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.150977 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 3.560009  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152511 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 3.545083  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.151498 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 3.464070  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.160359 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 3.395850  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154880 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 3.353376  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.149859 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 3.294239  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.160149 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 3.224964  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.163325 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 3.249203  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.158999 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 3.150325  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.160952 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 3.140551  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155093 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 3.098990  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.142916 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 3.040305  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.159694 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 3.019238  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.159454 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.984061  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.150902 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 2.949554  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.158370 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 2.898914  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152196 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 2.875656  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.157498 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 2.840833  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.156033 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 2.827872  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.153904 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 2.797603  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.150800 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 2.773092  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.157813 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 2.755122  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.153484 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 2.732725  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.144276 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 2.704287  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152579 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 2.687497  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154952 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 2.674487  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.156138 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 2.656458  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.151636 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 2.638573  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.156522 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 2.618141  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.158442 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 2.597772  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.158091 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 2.605354  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.146334 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 2.572396  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.156417 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 2.575612  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.157115 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 2.548340  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.146055 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 2.548195  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154988 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 2.547404  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.151567 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 2.537055  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155021 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 2.522732  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.157046 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 2.522933  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155581 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 2.513765  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.160497 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 2.510693  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.149090 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 2.506495  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.153730 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 2.501236  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.153451 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 2.499942  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.149824 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 2.490246  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.148008 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 2.485577  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.153904 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 2.483399  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.153733 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 2.485023  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154185 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 2.475543  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152370 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 2.468265  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154044 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 2.470643  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152475 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 2.463018  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152720 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 2.466316  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154290 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 2.459171  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.150695 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 2.467952  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.149928 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 2.455105  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152298 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 2.451484  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152022 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 2.448960  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152055 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 2.444777  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.157324 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 2.447647  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.153068 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 2.446450  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152406 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 2.448262  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.150800 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 2.454185  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155479 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 2.441224  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.149683 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 2.444356  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.153209 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 2.447580  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.156276 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 2.440695  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154602 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 2.443652  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154778 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 2.441662  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155126 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 2.433301  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.149859 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 2.432934  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154044 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 2.434875  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.158022 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 2.432029  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.156453 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 2.436080  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.159700 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 2.429469  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154116 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 2.428486  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154673 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 2.433208  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.161234 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 2.425912  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155266 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 2.428287  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155614 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 2.429636  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.158999 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 2.430625  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.156731 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 2.426655  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155231 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 2.425534  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155788 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 2.424096  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.153520 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 2.420369  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155126 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 2.421199  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.158649 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 2.418245  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.156381 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 2.420496  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.161791 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 2.412142  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154637 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 2.416607  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.159454 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 2.420743  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.157986 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 2.416226  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154290 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 2.419621  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.153559 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 2.417165  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154464 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 2.422459  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.158682 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 2.411025  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.157852 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 2.407797  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154113 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 2.419581  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.157324 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 2.417956  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155228 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 2.417906  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154359 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 2.422938  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.158684 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 2.416958  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.156486 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 2.423075  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152966 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 2.405186  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.151882 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 2.407304  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152124 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 2.415872  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154952 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 2.419113  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152546 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 2.413663  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155997 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 2.406530  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.155266 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 2.410576  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.154218 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 2.407513  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.157465 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 2.409464  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.152370 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 2.406598  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.149473 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 2.404629  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.150276 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.356284  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.940490 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.967978  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.870513 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.574649  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.793488 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.432009  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.766630 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.226361  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.759342 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.098824  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.736036 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.954050  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.704118 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.887583  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.709843 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.820233  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.683608 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.750871  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.668507 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.729159  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.655596 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.677765  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.638677 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.626082  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.650539 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2.597334  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.641643 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2.572732  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.640037 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 2.547834  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.620853 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 2.535975  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.616249 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 2.532777  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.627833 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 2.518598  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.616839 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 2.509444  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.613562 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 2.499676  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.598839 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 2.496140  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.602050 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 2.500980  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.610213 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2.487109  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.594199 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 2.479247  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.604596 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 2.468818  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.599543 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2.467671  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.583283 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 2.464064  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.583004 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.463269  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.593399 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.462651  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.591377 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 2.460005  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.586913 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 2.460675  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.586075 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 2.452141  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.585970 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 2.447985  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.585062 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 2.445950  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.575435 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 2.447774  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.582381 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 2.448047  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.571214 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 2.439619  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.576135 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 2.445900  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.576204 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 2.436649  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.577741 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 2.442591  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.572469 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 2.444010  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.578469 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 2.443023  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.569327 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 2.428080  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.568844 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 2.434115  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.559911 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 2.439074  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.557054 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 2.439243  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.571145 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 2.432987  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.562982 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 2.436985  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.560364 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 2.431194  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.560993 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 2.430757  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.561481 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 2.426820  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.557677 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 2.425748  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.568913 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 2.428101  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.561307 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 2.430091  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.554924 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 2.428327  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.557752 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 2.430499  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.551713 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 2.424234  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.548435 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 2.418628  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.562287 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 2.423913  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.555586 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 2.425324  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.553840 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 2.424516  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.552797 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 2.428087  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.557048 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 2.432191  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.554816 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 2.424417  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.553357 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 2.421301  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.547354 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 2.419672  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.553528 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 2.427255  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.556949 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 2.423846  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.553076 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 2.417196  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.557090 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 2.417450  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.551153 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 2.424413  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.553282 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 2.420125  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.555310 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 2.415974  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.543238 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 2.419590  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.547564 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 2.416537  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.551749 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 2.420680  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.549448 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 2.417916  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.547006 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 2.421724  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.548366 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 2.422987  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.542888 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 2.424069  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.540063 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 2.416327  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.546656 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 2.414200  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.540833 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 2.420588  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.544568 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 2.416235  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.536297 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 2.421140  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.538388 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 2.417639  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.544319 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 2.414788  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.534551 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 2.422059  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.534554 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 2.414995  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.536294 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 2.415440  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.539053 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 2.416817  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.533329 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 2.413535  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.532598 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 2.414841  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.533997 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 2.419001  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.529003 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 2.413122  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.530609 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 2.410040  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.531864 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 2.417928  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.538391 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 2.416687  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.532909 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 2.421627  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.531310 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 2.412270  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.524360 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 2.412255  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.531693 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 2.412923  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.528967 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 2.417860  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.532181 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 2.418252  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.528973 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 2.422820  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.527014 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 2.415498  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.528203 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 2.410970  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.530543 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 2.406906  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.528970 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 2.409849  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.526670 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 2.418494  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.523216 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 2.415068  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.527436 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 2.414247  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.530438 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 2.418140  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.530019 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 2.409163  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.526912 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 2.416218  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.522377 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 2.415665  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.519378 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 2.417364  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.525028 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 2.412730  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.525067 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 2.409777  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.529216 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 2.411826  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.528482 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 2.413646  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.530851 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 2.416566  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.532319 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 2.412171  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.521640 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 2.412320  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.517527 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 2.407078  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.523180 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 2.411754  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.522521 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 2.413073  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.522380 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 2.411565  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.518642 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 2.403939  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.523213 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.026569  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.996756 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.830556  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.991070 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.705778  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.982350 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.643430  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.969337 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.600331  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.967315 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.555015  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.964664 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.535783  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.976245 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.507806  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.962708 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.487864  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.957966 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.482102  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.959919 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.465574  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.955594 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.464581  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.967001 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.451489  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.962046 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2.450105  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.955210 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2.443564  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.959778 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 2.444211  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.960998 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 2.446535  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.969337 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 2.436940  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.966686 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 2.430485  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.967630 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 2.429735  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.962675 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 2.434031  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.963442 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 2.430625  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.959326 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 2.424772  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.959359 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2.421196  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.961663 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 2.425371  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.958314 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 2.419659  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.960791 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2.420063  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.964140 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 2.420547  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.964802 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.418532  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.963268 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.418207  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.960581 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 2.416356  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.959221 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 2.419512  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.960686 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 2.425467  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.961384 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 2.415768  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.960476 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 2.416450  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.957792 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 2.421300  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.954443 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 2.416017  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.955803 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 2.411914  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.959536 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 2.413338  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.961453 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 2.418480  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.960650 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 2.419089  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.962187 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 2.415498  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.960024 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 2.413421  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.959919 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 2.415714  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.961315 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 2.418998  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.961699 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 2.416716  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.962885 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 2.410691  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.958559 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 2.411280  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.956639 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 2.414461  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.952943 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 2.417794  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.955489 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 2.407405  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.956118 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 2.413338  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.954827 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 2.416292  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.952733 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 2.410947  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.950570 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 2.408833  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.948964 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 2.417091  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.951058 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 2.410649  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.948827 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 2.416815  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.947536 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 2.407965  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.947221 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 2.410431  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.945268 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 2.408016  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.947326 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 2.408222  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.947221 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 2.410000  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.950918 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 2.407810  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.947047 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 2.408519  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.949803 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 2.404824  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.949141 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 2.405710  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.949141 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 2.405893  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.948758 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 2.405224  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.944534 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 2.401519  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.944570 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 2.412075  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.944258 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 2.404593  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.945340 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 2.405276  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.945861 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 2.403688  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.944989 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 2.405540  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.943174 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 2.406232  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.941535 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 2.405425  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.943453 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 2.404821  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.941814 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 2.406269  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.944360 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 2.404986  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.940104 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 2.407345  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.942931 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 2.404844  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.942826 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 2.403466  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.942302 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 2.410442  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.943803 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 2.406912  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.949944 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 2.404013  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.941814 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 2.405339  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.939058 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 2.400418  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.940002 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 2.405985  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.944222 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 2.397418  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.938920 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 2.400835  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.937072 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 2.404521  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.936928 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 2.397005  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.934421 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 2.400512  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.936757 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 2.399775  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.936233 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 2.398494  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.940631 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 2.405441  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.938675 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 2.402611  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.940559 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 2.404589  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.938465 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 2.406447  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.939130 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 2.393606  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.938848 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 2.405057  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.938779 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 2.405757  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.935955 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 2.392573  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.935011 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 2.396077  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.930269 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 2.398221  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.928873 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 2.399720  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.929083 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 2.408973  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.930512 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 2.392581  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.930685 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 2.397508  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.930023 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 2.398130  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.929814 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 2.397723  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.931000 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 2.397422  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.933966 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 2.398228  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.929604 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 2.394975  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.930688 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 2.394942  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.927579 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 2.400319  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.928490 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 2.398690  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.928768 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 2.396524  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.928454 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 2.393417  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.926920 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 2.393332  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.929152 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 2.397425  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.930269 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 2.393805  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.927756 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 2.394766  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.926884 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 2.396465  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.929188 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 2.392875  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.929047 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 2.396585  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.927339 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 2.396636  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.930374 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 2.400446  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.931419 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 2.399396  [    0/ 3734]\n",
      "Test Error: \n",
      " Avg accuracy: 0.924721 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "model_file = 'models/selective-hubert-10ep-100c.pt' # 80c is 80% coverage\n",
    "\n",
    "train_losses_file = 'logs/selective-hubert-10ep-100c-train'\n",
    "test_losses_file = 'logs/selective-hubert-10ep-100c-test'\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "t = trange(num_epochs)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "fold_set = set([fold00, fold01, fold02])\n",
    "fold_models = []\n",
    "\n",
    "for i, fold in enumerate(fold_set):\n",
    "    off_folds = fold_set.difference([fold])\n",
    "    off_concat = torch.utils.data.ConcatDataset(off_folds)\n",
    "        \n",
    "    train_loader = DataLoader(off_concat, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "    test_loader = DataLoader(fold, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "    \n",
    "    for epoch in t:\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "        train_loss, train_loss_dict = selective_train(train_loader, model, loss_fn, optimizer, device)\n",
    "        test_loss, test_loss_dict = selective_test(test_loader, model, loss_fn, device)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    \n",
    "    with open(f'{train_losses_file}_fold_{str(i)}.txt', 'w') as fp:\n",
    "        for s in train_losses:\n",
    "            fp.write(\"%s\\n\" % s)\n",
    "            \n",
    "    with open(f'{test_losses_file}_fold_{str(i)}.txt', 'w') as fp:\n",
    "        for x in test_losses:\n",
    "            fp.write(\"%s\\n\" % x)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ccce7f6-6d65-42a5-9b8c-bb6b5d4c949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 000\n",
      "Test Error: \n",
      " Avg accuracy: 1.000000 \n",
      "\n",
      "Fold 001\n",
      "Test Error: \n",
      " Avg accuracy: 1.000000 \n",
      "\n",
      "Fold 002\n",
      "Test Error: \n",
      " Avg accuracy: 0.923883 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "model = HuBERTSelectiveNet(num_classes=num_classes, feature_size=feature_size)\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "model.eval()\n",
    "\n",
    "loss_fn = SelectiveLoss(loss_func, coverage, alpha, lm, device=device)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "predictions_file = 'logs/selective-hubert-10ep-100c-predictions'\n",
    "selections_file = 'logs/selective-hubert-10ep-100c-selections'\n",
    "auxiliary_file = 'logs/selective-hubert-10ep-100c-auxiliary'\n",
    "\n",
    "loss_dict_file = 'logs/selective-hubert-10ep-100c-loss-dict'\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, fold in enumerate(fold_set):\n",
    "    print(f'Fold 00{i}')\n",
    "        \n",
    "    test_loader = DataLoader(fold, batch_size=batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "\n",
    "    loss_fn = SelectiveLoss(loss_func, coverage, alpha, lm, device=device)\n",
    "\n",
    "    pred = []\n",
    "    selection = []\n",
    "    aux = []\n",
    "    for X, y in test_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits, selection_logits, auxiliary_logits = model(X)\n",
    "        pred.append(logits.detach().cpu().numpy())\n",
    "        selection.append(selection_logits.detach().cpu().numpy())\n",
    "        aux.append(auxiliary_logits.detach().cpu().numpy())\n",
    "\n",
    "    test_loss, test_loss_dict = selective_test(test_loader, model, loss_fn, device)\n",
    "    \n",
    "    test_loss_dict['loss'] = test_loss_dict['loss'].detach().cpu().item()\n",
    "    test_loss_dict['loss_pytorch'] = test_loss_dict['loss_pytorch'].detach().cpu().item()\n",
    "    \n",
    "    with open(f'{loss_dict_file}_fold_{str(i)}', 'w') as fp: \n",
    "            fp.write(json.dumps(test_loss_dict))\n",
    "\n",
    "    np.save(f'{predictions_file}_fold_{str(i)}.npy', np.array(pred, dtype='object'), allow_pickle=True) \n",
    "    np.save(f'{selections_file}_fold_{str(i)}.npy', np.array(selection, dtype='object'), allow_pickle=True)\n",
    "    np.save(f'{auxiliary_file}_fold_{str(i)}.npy', np.array(aux, dtype='object'), allow_pickle=True)\n",
    "        \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72315926-0b41-4c76-82bc-7372a496975d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a5faf-f60c-4ee8-86d2-4710bd351cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
